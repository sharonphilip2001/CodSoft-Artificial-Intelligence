# -*- coding: utf-8 -*-
"""task 4  recommendation system

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/196zcSf7hJypstlMe7kW7Q-suJ-_Tv0to
"""

import numpy as np
import pandas as pd
import sklearn
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from sklearn.neighbors import NearestNeighbors
from scipy.sparse import csr_matrix # Import csr_matrix

warnings.simplefilter(action='ignore', category=FutureWarning)

# Initialize ratings and movies dataframes outside the try block
# This ensures they exist even if data loading/processing fails
ratings = pd.DataFrame()
movies = pd.DataFrame()
matrix_created = False # Flag to track if the matrix was successfully created

# Load datasets from local files
# Make sure you have downloaded these files and placed them in the same directory
# as this notebook, or provide the correct path.
try:
    # Assuming 'Amazon.csv' has columns like 'user_id', 'Movie1', 'Movie2', ...
    # Note: The original code uses 'netflix_data.csv.zip' but comments mention 'Amazon.csv'.
    # Ensure the file path and column names ('user_id', 'MovieX') match the actual file content.
    amazon_data = pd.read_csv("/content/netflix_data.csv")
    print("Sample Amazon Data:")
    print(amazon_data.head())

    # --- Data Transformation: Melt the wide format data into a long format ---
    # Identify the user ID column (assuming it's 'user_id')
    user_id_column = 'user_id'
    # Identify the movie rating columns (assuming they are 'Movie1' to 'Movie206')
    # Adjust the range based on the actual column names in your Amazon.csv
    # Ensure 'amazon_data.columns' actually contains columns starting with 'Movie'
    movie_columns = [col for col in amazon_data.columns if col.startswith('Movie')]

    if not movie_columns:
        raise ValueError("No columns starting with 'Movie' found in the DataFrame. Please check the column names in your CSV file.")

    # Melt the DataFrame
    ratings = amazon_data.melt(
        id_vars=[user_id_column],
        value_vars=movie_columns,
        var_name='movieId_str', # Temporary name for movie column name
        value_name='rating'
    )

    # Convert movie_str to a numerical movieId (e.g., extract the number)
    # This assumes 'Movie1' -> 1, 'Movie2' -> 2, etc. Adjust if necessary.
    # Check if the conversion is possible before attempting
    try:
        ratings['movieId'] = ratings['movieId_str'].str.replace('Movie', '').astype(int)
    except ValueError:
        raise ValueError("Could not convert movie ID strings to integers. Ensure column names are in 'MovieX' format.")


    # Drop rows with missing ratings (NaN values introduced by melting)
    ratings.dropna(subset=['rating'], inplace=True)

    if ratings.empty:
         raise ValueError("Ratings DataFrame is empty after melting and dropping NaNs.")

    # Rename the user_id column to userId to match the rest of the code
    # Check if user_id_column exists before renaming
    if user_id_column not in ratings.columns:
         raise ValueError(f"User ID column '{user_id_column}' not found in the melted DataFrame.")
    ratings.rename(columns={user_id_column: 'userId'}, inplace=True)

    # Now, the 'ratings' DataFrame is in the expected format (userId, movieId, rating)

    # Create a 'movies' DataFrame from the unique movie IDs
    # We don't have movie titles in this dataset, so we'll just use the IDs.
    movies = pd.DataFrame({'movieId': ratings['movieId'].unique()})
    movies['title'] = 'Movie ' + movies['movieId'].astype(str) # Create dummy titles


except FileNotFoundError:
    print("Error: Make sure 'netflix_data.csv.zip' is in the correct directory.")
    # You might want to exit or handle this error appropriately
    # exit()
except Exception as e:
    print(f"An error occurred during data processing: {e}")
    # The ratings and movies dataframes remain empty or in their initial state


# Check if ratings DataFrame was successfully populated before printing/processing
if not ratings.empty:
    print("\nSample Processed Ratings (long format):")
    print(ratings.head())

    print("\nSample Processed Movies:")
    print(movies.head())

    # Basic stats
    n_ratings = len(ratings)
    # Use the newly created ratings DataFrame
    n_movies = ratings['movieId'].nunique()
    n_users = ratings['userId'].nunique()

    print(f"\nNumber of ratings: {n_ratings}")
    # Use the newly created ratings DataFrame
    print(f"Number of unique movieId's: {n_movies}")
    print(f"Number of unique users: {n_users}")
    print(f"Average ratings per user: {round(n_ratings/n_users, 2)}")
    print(f"Average ratings per movie: {round(n_ratings/n_movies, 2)}")


    user_freq = ratings[['userId', 'movieId']].groupby(
        'userId').count().reset_index()
    user_freq.columns = ['userId', 'n_ratings']
    print("\nUser Frequency:")
    print(user_freq.head())

    # Highest and lowest rated movies (by mean) - need enough ratings for meaningful stats
    # Filter out movies with very few ratings if needed
    mean_rating = ratings.groupby('movieId')[['rating']].mean()
    # Ensure there are ratings to calculate min/max
    if not mean_rating.empty:
        lowest_rated_id = mean_rating['rating'].idxmin()
        highest_rated_id = mean_rating['rating'].idxmax()

        # Ensure the movie IDs exist in the movies DataFrame
        lowest_movie = movies[movies['movieId'] == lowest_rated_id]
        highest_movie = movies[movies['movieId'] == highest_rated_id]

        print("\nLowest Rated Movie (by mean):")
        if not lowest_movie.empty:
             print(lowest_movie)
        else:
            print(f"Movie ID {lowest_rated_id} not found in the movies list.")


        print("\nHighest Rated Movie (by mean):")
        if not highest_movie.empty:
             print(highest_movie)
        else:
             print(f"Movie ID {highest_rated_id} not found in the movies list.")

    else:
        print("\nNot enough ratings to determine lowest/highest rated movies.")


    # Create matrix
    def create_matrix(df):
        # Add checks here to ensure necessary columns exist in the dataframe
        if 'userId' not in df.columns or 'movieId' not in df.columns or 'rating' not in df.columns:
             raise ValueError("DataFrame does not contain required columns (userId, movieId, rating) for matrix creation.")

        N = len(df['userId'].unique())
        M = len(df['movieId'].unique())

        if N == 0 or M == 0:
             raise ValueError("Cannot create matrix: No unique users or movies found.")

        user_mapper = dict(zip(np.unique(df["userId"]), list(range(N))))
        movie_mapper = dict(zip(np.unique(df["movieId"]), list(range(M))))

        user_inv_mapper = dict(zip(list(range(N)), np.unique(df["userId"])))
        movie_inv_mapper = dict(zip(list(range(M)), np.unique(df["movieId"])))

        # Use .map and .fillna(0) or similar if some IDs might not be in mappers
        # For now, assuming all IDs in df are in mappers due to unique()
        user_index = [user_mapper[i] for i in df['userId']]
        movie_index = [movie_mapper[i] for i in df['movieId']]

        # Ensure movie_index and user_index have the same length as ratings
        if len(user_index) != len(df) or len(movie_index) != len(df):
             raise ValueError("Mismatch in index lengths during matrix creation.")

        # The shape should be (M, N) for a movie-user matrix
        X = csr_matrix((df["rating"], (movie_index, user_index)), shape=(M, N))

        return X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper

    # Only create the matrix if the ratings DataFrame is not empty after processing
    try:
        X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper = create_matrix(ratings)
        matrix_created = True
        print("\nMatrix created successfully.")
    except Exception as e:
        print(f"Error creating matrix: {e}")
        matrix_created = False


    """
    Find similar movies using KNN
    """
    # Ensure the function handles the case where X is None or empty
    def find_similar_movies(movie_id, X, movie_mapper, movie_inv_mapper, k, metric='cosine', show_distance=False):
        if X is None or X.shape[0] == 0:
            print("Matrix X is not available or empty.")
            return []

        neighbour_ids = []

        # Use .get() with a default to handle cases where the movie_id might not be in the mapper
        movie_ind = movie_mapper.get(movie_id, None)
        if movie_ind is None or movie_ind >= X.shape[0]: # Also check if index is within matrix bounds
            print(f"Movie ID {movie_id} not found in the dataset or index out of bounds.")
            return []

        movie_vec = X[movie_ind]

        # Check if movie_vec is a valid vector
        if movie_vec.shape[1] == 0:
             print(f"Movie ID {movie_id} has no associated feature vector.")
             return []

        k_neighbors = k + 1 # include itself in the neighbors list initially
        # Ensure k_neighbors is not greater than the number of items in the matrix
        if k_neighbors > X.shape[0]:
             k_neighbors = X.shape[0]
             print(f"Warning: Requested k ({k}) is greater than the number of unique movies ({X.shape[0]}). Reducing k to {k_neighbors-1}.")


        kNN = NearestNeighbors(n_neighbors=k_neighbors, algorithm="brute", metric=metric)
        try:
            kNN.fit(X)
            movie_vec = movie_vec.reshape(1,-1)
            # The kneighbors method returns distances and indices in a tuple
            # Add error handling for kneighbors if the vector is problematic
            neighbour = kNN.kneighbors(movie_vec, return_distance=show_distance)
        except Exception as e:
             print(f"Error during KNN kneighbors calculation: {e}")
             return []


        # Extract the indices from the result
        # Ensure the structure of 'neighbour' is as expected
        if show_distance:
             if len(neighbour) < 2 or len(neighbour[1]) == 0:
                  print("KNN kneighbors did not return expected indices.")
                  return []
             neighbour_indices = neighbour[1].flatten()
        else:
             if len(neighbour) == 0 or len(neighbour[0]) == 0:
                  print("KNN kneighbors did not return expected indices.")
                  return []
             neighbour_indices = neighbour[0].flatten()


        for n_index in neighbour_indices:
            # Use .get() with a default to handle cases where the index might not be in the inverse mapper
            neighbour_ids.append(movie_inv_mapper.get(n_index, None))

        # Filter out None values and the original movie_id if it's included
        neighbour_ids = [id for id in neighbour_ids if id is not None and id != movie_id]

        # Return only the top k requested neighbors
        return neighbour_ids[:k] # return k neighbors (excluding the original movie)


    # Recommend movies for a user
    # Ensure the function checks if necessary mappers and dataframes exist
    def recommend_movies_for_user(user_id, X, user_mapper, movie_mapper, movie_inv_mapper, movies_df, ratings_df, k=10):
        # Check if necessary components are available
        if X is None or user_mapper is None or movie_mapper is None or movie_inv_mapper is None or movies_df.empty or ratings_df.empty:
             print("Recommendation components are not fully initialized.")
             return

        # Use the processed ratings DataFrame
        df1 = ratings_df[ratings_df['userId'] == user_id]

        if df1.empty:
            print(f"User with ID {user_id} does not exist or has no ratings.")
            return

        # Get the movie ID with the highest rating for this user
        # Use .iloc[0] to handle cases where multiple movies have the same max rating
        # Add error handling in case df1 is unexpectedly empty here
        try:
            movie_id = df1[df1['rating'] == max(df1['rating'])]['movieId'].iloc[0]
        except Exception as e:
             print(f"Error finding highest rated movie for user {user_id}: {e}")
             return


        # Create a dictionary for movie titles from the movies DataFrame
        movie_titles = dict(zip(movies_df['movieId'], movies_df['title']))

        # Pass movie_mapper and movie_inv_mapper to find_similar_movies
        similar_ids = find_similar_movies(movie_id, X, movie_mapper, movie_inv_mapper, k)

        # Get the title of the watched movie
        movie_title = movie_titles.get(movie_id, f"Movie ID {movie_id} not found in movies list")

        if not similar_ids:
            print(f"Could not find similar movies for '{movie_title}' (Movie ID: {movie_id}).")
            return

        print(f"\nSince you watched '{movie_title}', you might also like:")
        for i in similar_ids:
            # Get titles for recommended movies
            print(movie_titles.get(i, f"Movie ID {i} not found in movies list"))

    # Try recommending for known users
    # Check if the matrix was successfully created before attempting recommendations
    if matrix_created:
        user_id = 150
        # Pass the necessary variables including the processed movies and ratings DataFrames
        recommend_movies_for_user(user_id, X, user_mapper, movie_mapper, movie_inv_mapper, movies, ratings, k=10)

        user_id = 2300
        # Pass the necessary variables including the processed movies and ratings DataFrames
        recommend_movies_for_user(user_id, X, user_mapper, movie_mapper, movie_inv_mapper, movies, ratings, k=10)
    else:
        print("Skipping recommendations as the matrix could not be created.")

else:
    print("\nSkipping further processing and recommendations as the ratings DataFrame is empty.")

# Install gradio if needed
!pip install gradio

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import gradio as gr

# Load dataset
df = pd.read_csv("/content/netflix_data.csv")[['title', 'description']].dropna().drop_duplicates()

# TF-IDF and similarity matrix
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df['description'])
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# Title to index mapping
title_to_index = pd.Series(df.index, index=df['title']).drop_duplicates()

# Recommendation function
def recommend(title):
    if title not in title_to_index:
        return "Title not found. Try another Netflix title."
    idx = title_to_index[title]
    sim_scores = sorted(list(enumerate(cosine_sim[idx])), key=lambda x: x[1], reverse=True)[1:6]
    recommendations = [df['title'].iloc[i[0]] for i in sim_scores]
    return "\n".join(recommendations)

# Gradio interface
gr.Interface(
    fn=recommend,
    inputs=gr.Textbox(label="Enter a Netflix Title"),
    outputs="text",
    title="Netflix Recommendation System",
    description="Get content-based recommendations using description similarity."
).launch()